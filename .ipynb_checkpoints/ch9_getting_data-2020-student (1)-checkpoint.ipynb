{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math, random, csv, json, re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If some module is not installed, for example, beautifulsoup,\n",
    "- googling: anaconda how to install beautifulsoup\n",
    "- Find anaconda cloud in google answer, where the modules are tested and safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a data scientist you will spend an **embarrassingly large fraction of your time** \n",
    "- acquiring, \n",
    "- cleaning, \n",
    "- and transforming data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## stdin and stdout\n",
    "\n",
    "### Number of lines containing numbers\n",
    "- You could then use these to count how many lines of a file contain numbers.\n",
    "- you can pipe data through them using sys.stdin and sys.stdout ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# egrep.py\n",
    "import sys, re\n",
    "\n",
    "# sys.argv is the list of command-line arguments\n",
    "# sys.argv[0] is the name of the program itself\n",
    "# sys.argv[1] will be the regex specified at the command line\n",
    "regex = sys.argv[1]\n",
    "\n",
    "# for every line passed into the script\n",
    "for line in sys.stdin:\n",
    "    # if it matches the regex, write it to stdout\n",
    "    if re.search(regex, line):\n",
    "        sys.stdout.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# line_count.py\n",
    "import sys\n",
    "\n",
    "count = 0\n",
    "for line in sys.stdin:\n",
    "    count += 1\n",
    "    \n",
    "# print goes to sys.stdout\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "지정된 파일을 찾을 수 없습니다.\n",
      "python: can't open file 'egrep.py': [Errno 2] No such file or directory\n",
      "python: can't open file 'line_count.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# windows \n",
    "\n",
    "!type the_bible.txt | python egrep.py \"[0-9]\" | python line_count.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Linux\n",
    "\n",
    "!cat the_bible.txt | python egrep.py \"[0-9]\" | python line_count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Most Common Words\n",
    "\n",
    "- a script that counts the words in its input and writes out the most common ones"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "most_common_words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: most_common_words.py num_words\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-29ce76b37d99>\", line 6, in <module>\n",
      "    num_words = int(sys.argv[1])\n",
      "ValueError: invalid literal for int() with base 10: '-f'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\leese\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-29ce76b37d99>\", line 9, in <module>\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\leese\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\leese\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\leese\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\leese\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leese\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "# pass in number of words as first argument\n",
    "try:\n",
    "    num_words = int(sys.argv[1])\n",
    "except:\n",
    "    print(\"usage: most_common_words.py num_words\")\n",
    "    sys.exit(1)\n",
    "\n",
    "counter = Counter(word.lower()                        # non-zero exit code indicates error\n",
    "                  for line in sys.stdin               # lowercase words\n",
    "                  for word in line.strip().split()    # split on spaces\n",
    "                  if word)                            # skip empty 'words'\n",
    "\n",
    "for word, count in counter.most_common(num_words):\n",
    "    sys.stdout.write(str(count))\n",
    "    sys.stdout.write(\"\\t\")\n",
    "    sys.stdout.write(word)\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "지정된 파일을 찾을 수 없습니다.\n",
      "python: can't open file 'most_common_words.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# windows\n",
    "\n",
    "!type the_bible.txt | python most_common_words.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Basics of Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 'r' means read-only\n",
    "file_for_reading = open('reading_file.txt', 'r')\n",
    "\n",
    "# 'w' is write—will destroy the file if it already exists!\n",
    "file_for_writing = open('writing_file.txt', 'w')\n",
    "\n",
    "# 'a' is append—for adding to the end of the file\n",
    "file_for_appending = open('appending_file.txt', 'a')\n",
    "\n",
    "# don't forget to close your files when you're done\n",
    "file_for_writing.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Because it is easy to forget to close your files, you should always use them in a **with**\n",
    "block, at the end of which they will be **closed automatically**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(filename,'r') as f:\n",
    "    data = function_that_gets_data_from(f)\n",
    "\n",
    "# at this point f has already been closed, so don't try to use it\n",
    "process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "starts_with_numbers = 0\n",
    "\n",
    "with open('the_bible.txt','r') as file:\n",
    "    for line in file:                 # look at each line in the file\n",
    "        if re.match(\"^[0-9]\", line):       # use a regex to see if it starts with '#'\n",
    "            starts_with_numbers += 1     # if it does, add 1 to the count\n",
    "            \n",
    "starts_with_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_domain(email_address):\n",
    "    \"\"\"split on '@' and return the last piece\"\"\"\n",
    "    return email_address.lower().split(\"@\")[-1]\n",
    "\n",
    "with open('email_addresses.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip())\n",
    "                            for line in f\n",
    "                            if \"@\" in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Delimited Files\n",
    "\n",
    "- csv file : These files are very often either comma-separated or tab-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!type tab_delimited_stock_prices.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tab_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        print(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!type colon_delimited_stock_prices.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open('colon_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=':')\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        closing_price = float(row[\"closing_price\"])\n",
    "        print(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!type comma_delimited_stock_prices_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "today_prices = { 'AAPL' : 90.91, 'MSFT' : 41.68, 'FB' : 64.5 }\n",
    "\n",
    "with open('comma_delimited_stock_prices_1.txt','w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in today_prices.items():\n",
    "        writer.writerow([stock, price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!type bad_csv.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "results = [[\"test1\", \"success\", \"Monday\"],\n",
    "           [\"test2\", \"success, kind of\", \"Tuesday\"],\n",
    "           [\"test3\", \"failure, kind of\", \"Wednesday\"],\n",
    "           [\"test4\", \"failure, utter\", \"Thursday\"]]\n",
    "\n",
    "# don't do this!\n",
    "with open('bad_csv.txt', 'w') as f:\n",
    "    for row in results:\n",
    "        f.write(\",\".join(map(str, row))) # might have too many commas in it!\n",
    "        f.write(\"\\n\")                    # row might have newlines as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping the Web\n",
    "\n",
    "- Another way to get data is by scraping it from web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### HTML and Parsing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<html>\n",
    "  <head>\n",
    "    <title>A web page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <p id=\"author\">Joel Grus</p>\n",
    "    <p id=\"subject\">Data Science</p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for python3:\n",
    "    - pip install html5lib\n",
    "    - pip install beautifulsoup4\n",
    "\n",
    "- for anaconda\n",
    "    - conda install -c anaconda html5lib\n",
    "         - https://anaconda.org/anaconda/html5lib\n",
    "    - conda install -c anaconda beautifulsoup4\n",
    "        - https://anaconda.org/anaconda/beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Olfa_Nasraoui/publication/221417012/figure/download/fig2/AS:669043992322053@1536523926785/Dom-Tree-of-An-Example-Web-Page.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "    <h1>DOM Lesson one</h1>\n",
    "    <p>Hello World!</p>\n",
    "    <table>\n",
    "        <tr class=\"people\">\n",
    "            <td>John</td>\n",
    "            <td>Doe</td>\n",
    "            <td>Alaska</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>A web page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <p id=\"author\">Joel Grus</p>\n",
    "    <p id=\"subject\">Data Science</p>\n",
    "    <p class=\"price\">30</p>\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 1: Find **title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 2: Find **title**'s **text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 3: Find **p** of **body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 4: Find all **p** under **body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 5: Find second **p**'s **text** of **body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body('p')[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 6: Find last **p** of **body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body('p')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 7: Loop over all **p** of **body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, p in enumerate(soup.body('p')):\n",
    "    print('paragraph {}: {}'.format(i, p.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 8: Find first **p**'s **id** attribute's value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.p['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 9: Find all **p** whose attribute **id** is 'author'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup('p', {'id':'author'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 10: Find all **p** whose attribute **class** is 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup('p', 'price')\n",
    "#soup('p', {'class':'price'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query 11: Find all **text**s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "first_paragraph = soup.find('p')     # or just soup.p\n",
    "print(first_paragraph)\n",
    "print(type(first_paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "first_paragraph_words = soup.p.text.split()\n",
    "first_paragraph_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "first_paragraph_id = soup.p['id']        # raises KeyError if no 'id'\n",
    "first_paragraph_id\n",
    "#type(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "first_paragraph_id2 = soup.p.get('id')   # returns None if no 'id'\n",
    "first_paragraph_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "all_paragraphs = soup.find_all('p')      # or just soup('p')\n",
    "all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup('p', {'id':'subject'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]\n",
    "paragraphs_with_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "important_paragraphs = soup('p', {'class' : 'important'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "html = requests.get(\"http://www.naver.com\").text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# warning, will return the same span multiple times\n",
    "# if it sits inside multiple divs\n",
    "# be more clever if that's the case\n",
    "spans_inside_divs = [span\n",
    "                     for div in soup('div')    # for each <div> on the page\n",
    "                     for span in div('span')]  # find each <span> inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spans_inside_divs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- 한국외국어대학교 도서관에서 big data로 검색한 단행본의 연도별 단행본의 수를 bar chart로 나타내시오.\n",
    "- 정말 지저분한 데이터\n",
    "- 요즘 웹 페이지들에서 데이터를 추출하려면, javascript를 수행한 결과를 봐야하기 때문에 어렵다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://library.hufs.ac.kr/yongin/search/Search.Result.ax?sid=1&q=ALL%3Abig+data&eq=&mf=true&qt=%EC%A0%84%EC%B2%B4%3Dbig+data&qf=big+data&f=%28CLASSID%3A%281+OR+2%29%29&br=&cl=1+2+3+4+6+7+9+10+41+42+31+32+33+36+37+34+35+15+16+23+24+25+26+27+28+29+30+11+12+13+14+17+18+19+20+21+22&gr=1+2+3+4+5+6+7+8&rl=&page=1&pageSize=10&s=S_PYB&st=DESC&h=&cr=&py=&subj=&facet=Y&nd=&vid=0&tabID="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import requests, re\n",
    "\n",
    "# you don't have to split the url like this unless it needs to fit in a book\n",
    "def extract_years(pnum):\n",
    "    url =\"https://library.hufs.ac.kr/yongin/search/Search.Result.ax?sid=1&q=ALL%3Abig+data&eq=&mf=true&qt=%EC%A0%84%EC%B2%B4%3Dbig+data&qf=big+data&f=%28CLASSID%3A%281+OR+2%29%29&br=&cl=1+2+3+4+6+7+9+10+41+42+31+32+33+36+37+34+35+15+16+23+24+25+26+27+28+29+30+11+12+13+14+17+18+19+20+21+22&gr=1+2+3+4+5+6+7+8&rl=&page=\" + \\\n",
    "         str(pnum) + \"&pageSize=10&s=S_PYB&st=DESC&h=&cr=&py=&subj=&facet=Y&nd=&vid=0&tabID=\"\n",
    "    hufs_lib_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(hufs_lib_text, 'html5lib')\n",
    "\n",
    "    booklist = soup('dl', 'bookList')\n",
    "    print(len(booklist))\n",
    "    regex = re.compile('\\d{4}\\.')\n",
    "    years = []\n",
    "    for book in booklist:\n",
    "    #    print(book.find('a', 'title').text)\n",
    "#         print(book.find('div', 'body').text)\n",
    "        years.append(int(regex.findall(book.find('div', 'body').text)[0][:-1]))\n",
    "\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "PAGENUM = 12\n",
    "years = []\n",
    "for pnum in range(1, PAGENUM + 1):\n",
    "    years += extract_years(pnum)\n",
    "    \n",
    "print(len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fd = Counter(years)\n",
    "print(fd)\n",
    "plt.bar(fd.keys(), fd.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### JSON as Tree Data Model\n",
    "- MongoDB is JSON-style tree database\n",
    "- JSON as Python dictionay of dictionaries of dictionaries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "                  \"author\" : \"Joel Grus\",\n",
    "                  \"publicationYear\" : 2014,\n",
    "                  \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "\n",
    "# parse the JSON to create a Python dict\n",
    "deserialized = json.loads(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "deserialized['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "deserialized['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "deserialized['publicationYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "deserialized['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "if \"data science\" in deserialized[\"topics\"]:\n",
    "    print(deserialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- To install various parser:\n",
    "    \n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### XML as Tree Data Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "tag, attribute, text에 대해 설명할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "xml_text = \"\"\"\n",
    "<Book>\n",
    "  <Title>Data Science Book</Title>\n",
    "  <Author>Joel Grus</Author>\n",
    "  <PublicationYear>2014</PublicationYear>\n",
    "  <Topics>\n",
    "    <Topic>data</Topic>\n",
    "    <Topic>science</Topic>\n",
    "    <Topic>data science</Topic>\n",
    "  </Topics>\n",
    "</Book>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(xml_text, 'lxml')\n",
    "\n",
    "soup.book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 1: Find **title** of **book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.book.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 2: Find **title**'s text of **book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.book.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 3: Find **author** of **book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.book.author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 4: Find all **topic** under **topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.topics('topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 5: Find second **topic**'s **text** of **topics** of **book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.book.topics('topic')[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 6: Find last **topic** of **book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.book('topic')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Query 7: Loop over all **topic** of **book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, topic in enumerate(soup.book('topic')):\n",
    "    print('topic {}: {}'.format(i, topic.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Overall Exercise)\n",
    "\n",
    "Query 8: Find the **title**'s **text** of all **books**s whose **author** is 'Joel Grus' and **publicationyear** >= 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in soup('book'):\n",
    "    if book.author.text == 'Joel Grus' and int(book.publicationyear.text) >= 2000:\n",
    "        print(book.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.topic.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.find('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.find_all('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using an Unauthenticated API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "endpoint = \"https://api.github.com/users/joelgrus/repos\"\n",
    "\n",
    "repos = json.loads(requests.get(endpoint).text)\n",
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)\n",
    "\n",
    "print(month_counts)\n",
    "print(weekday_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "last_5_repositories = sorted(repos,\n",
    "                             key=lambda r: r[\"created_at\"],\n",
    "                             reverse=True)[:5]\n",
    "\n",
    "last_5_languages = [repo[\"language\"]\n",
    "                    for repo in last_5_repositories]\n",
    "\n",
    "last_5_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding APIs\n",
    "\n",
    "- Try searching the Web for “python __ api” to find a library\n",
    "- Klout API, Yelp API, IMDB API, and so on.\n",
    "- <a href=\"http://bit.ly/1L35VOR\">Python for Beginners</a>\n",
    "- <a href=\"http://www.programmableweb.com\">Programmable Web</a>\n",
    "- <a href=\"https://www.data.go.kr/\">공공데이터포털</a>\n",
    "\n",
    "- Big Data: API의 시대\n",
    "\n",
    "https://www.data.go.kr/dataset/15000583/openapi.do\n",
    "\n",
    "https://www.data.go.kr/dataset/15003419/fileData.do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Using the Twitter APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Getting Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Go to https://apps.twitter.com/.\n",
    "2. If you are not signed in, click Sign in and enter your Twitter username and password.\n",
    "3. Click Create New App.\n",
    "4. Give it a name (such as “Data Science”) and a description, and put any URL as the website (it doesn’t matter which one).\n",
    "5. Agree to the Terms of Service and click Create.\n",
    "6. Take note of the consumer key and consumer secret.\n",
    "7. Click “Create my access token.”\n",
    "8. Take note of the access token and access token secret (you may have to refresh the page)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Twython\n",
    "\n",
    "- First we’ll look at the Search API, which requires only the consumer key and secret, not the access token or secret\n",
    "- Twitter search:\n",
    "    - https://developer.twitter.com/en/docs/tweets/search/overview\n",
    "- Twitter search API data format:\n",
    "    - https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY=\".....\"\n",
    "CONSUMER_SECRET=\".....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "\n",
    "twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "# search for tweets containing the phrase \"data science\"\n",
    "for status in twitter.search(q='\"trump\"')[\"statuses\"]:\n",
    "    user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "    text = status[\"text\"].encode('utf-8')\n",
    "    print(user, \":\", text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "\n",
    "# fill these in if you want to use the code\n",
    "CONSUMER_KEY = \"...\"\n",
    "CONSUMER_SECRET = \"...\"\n",
    "ACCESS_TOKEN = \"...\"\n",
    "ACCESS_TOKEN_SECRET = \"...\"\n",
    "\n",
    "def call_twitter_search_api():\n",
    "\n",
    "    twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    # search for tweets containing the phrase \"data science\"\n",
    "    for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "        user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "        text = status[\"text\"].encode('utf-8')\n",
    "        print(user, \":\", text)\n",
    "        print()\n",
    "\n",
    "from twython import TwythonStreamer\n",
    "\n",
    "# appending data to a global variable is pretty poor form\n",
    "# but it makes the example much simpler\n",
    "tweets = []\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    \"\"\"our own subclass of TwythonStreamer that specifies\n",
    "    how to interact with the stream\"\"\"\n",
    "\n",
    "    def on_success(self, data):\n",
    "        \"\"\"what do we do when twitter sends us data?\n",
    "        here data will be a Python object representing a tweet\"\"\"\n",
    "\n",
    "        # only want to collect English-language tweets\n",
    "        if data['lang'] == 'en':\n",
    "            tweets.append(data)\n",
    "\n",
    "        # stop when we've collected enough\n",
    "        #if len(tweets) >= 1000:\n",
    "        if len(tweets) >= 10:\n",
    "            self.disconnect()\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "\n",
    "def call_twitter_streaming_api():\n",
    "    stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET,\n",
    "                        ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "    # starts consuming public statuses that contain the keyword 'data'\n",
    "    stream.statuses.filter(track='trump')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def call_twitter_search_api():\n",
    "\n",
    "    twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    # search for tweets containing the phrase \"data science\"\n",
    "    for status in twitter.search(q='\"김정은\"')[\"statuses\"]:\n",
    "        user = status[\"user\"][\"screen_name\"]\n",
    "        text = status[\"text\"]\n",
    "        print(user, \":\", text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for status in twitter.search(q='\"손흥민\"')[\"statuses\"]:\n",
    "    user = status[\"user\"][\"screen_name\"]\n",
    "    text = status[\"text\"]\n",
    "    print(user, \":\", text)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
